---
title: "R Data Wrangling" 
theme: readable
output:
  html_document:
    toc: true
    toc_float: true
    fig_width: 12
    fig_height: 7
---

```{r chunksetup, include=FALSE, message =F, warning = F} 
library(here)
library(tidyverse)
library(tibble)
```

## What is data wrangling 

> It is often said that 80% of data analysis is spent on the process of cleaning and preparing the data (Dasu and Johnson 2003). 

At its heart, data wrangling is the set of techniques to get data into a usable form for analysis and visualization. 

Data wrangling is a catchall for data importing, data cleaning, and data transformation to create some product with the finished data. 


## Tidy data 

All messy data is unhappy in its own way. To put some structure on data, we prefer that our data is *tidy*. In tidy data, every column is a variable, every row is an observation, and every cell is a single value (Wickham 2014). 

Tidy datasets provide a standardized way to link the physical appearance of the dataset with its meaning (Wickham 2014). Datasets are made of **rows** and **columns** that contain a collection of **values** 

## The Tidyverse 

The tidyverse is a core set of packages that most R programmers use daily for everyday data science tasks. We can load this set of packages all at once with: 

```{r, message = F, warning = F}
library(tidyverse)
```

Alternatively, we can load individual packages from the tidyverse. For example, we can load the `dplyr` package. 

```{r, message = F, warning = F}
library(dplyr)
```


## The Grammar of Data Wrangling

The dplyr package provides many very useful functions for manipulating data frames. These functions will save you time by reducing repetition. As a bonus, you might even find the `dplyr` grammar easier to read.

In this workshop, we will cover five of the most commonly used functions and use pipes (`%>%`) to combine them.

1. `filter()`: pick out observations based on their values
2. `select()`: pick certain columns by name
3. `group_by()`: group observations based on a variable
4. `summarize()`: summarize observations based on some function 
6. `mutate()`: create new variables with function of existing variables

Each of these verbs works similarly. The first argument is always a data frame object. The additional arguments describe what to do with the data frame using unquoted variable names. The result is a new data frame. 

## Pipes 

A pipe operator `%>%` or `|>` is a method of chaining together functions. A pipe takes what is on the left-hand side of the pipe and makes it the first argument of the function on the right-hand side by default. 

```{r, eval = F}
## Pseudo code 
x %>% f(y) 

## is equivalent to 
f(x, y)

## where f() is a function 
```

The advantage of the tidyverse is that every function presumes that the first argument is a tidy data object. It is possible to put the left-hand side result as a different argument for the function on the right-hand side by explicitly specifying it. However, a well-written workflow tends to obviate the need to do so. 

The tidyverse is built around pipes because the first argument of every function in the tidyverse is a data frame, which means that the tidyverse all follows the same structure. When doing data tasks, having the same structure turns out to be very useful because it is easy to reason about what a function will do and what it needs. 

## London Animal Rescue Dataset 

To show the benefits of the `dplyr` verbs, we will start by working with a dataset of animal rescue incidents by the London Fire Brigade from 2009-2021. The data provides information on all incidents and information on the location, date and time, number of fire trucks, and cost of the rescue. 

```{r}
animals <- read_csv(here("R-Data-Wrangling-Module/data/animalRescue.csv"), show_col_type = FALSE)
View(animals)
```


## filter()

Suppose we are interested in looking at animal rescues from 2018-2020. `filter()` allows us to subset observations based on their value. 

Since we are introducing a verb explicitly for the first time, we will show the verb with and without pipes. The API is the same for every verb. 

```{r}
## Get all observations from the Year 2015 
filter(animals, Year == 2015)

## Get all observations from 2018-2020 
filter(animals, Year >= 2018 & Year <=2020)

```

The first argument is the name of the data frame we want to use, in this case, "animals." The arguments after are the expressions that filter the data frame. 

Here is the same code with a pipe and a neat shortcut 

```{r}
animals %>% 
  filter(Year == 2015)

animals %>% 
  filter(Year >= 2018 & Year <= 2020)

## which is the same as 
animals %>% 
  filter(between(Year, 2018, 2020))
```

As with the examples we have seen before, we take the animals data frame and then pass it via the pipe to the filter argument. Because the pipe puts the data frame as the first argument for every tidyverse function, we only have to specify the subsequent arguments. `between()` is a `dplyr` function that is a shortcut for x >= left & x <= right where x is our variable of interest.

Note that `between()` will not work if you want to exclude an endpoint.

 
 You can extend filter() with logical conditions:
 
| Symbol                 | Meaning                  |
|------------------------|--------------------------|
| <                      | less than                |
| >                      | greater than             |
| ==                     | equal to                 |
| <=                     | less than or equal to    |
| >=                     | greater than or equal to |
| !=                     | not equal to             |
| %in%                   | group membership         |
|is.na                   | is NA                    |
| !is.na                 | is not NA                |
|&, \|, !, xor, any, all | Boolean operators        |

## Multiple Filters at once 

Sometimes we want to filter multiple conditions at once. For example, we might be interested in all rescues of birds or horses after 2011. We use the `,` in our filter expression to accomplish this. 

```{r}
birds_and_horses <- animals %>% 
  filter(Type == "Bird" | Type == "Horse", Year > 2011)
View(birds_and_horses)
```

We can put multiple `filter` functions in a row in a piped workflow, though it does not look as readable. 

```{r}
birds_and_horses2 <- animals %>% 
  filter(Type == "Bird"|Type == "Horse")%>%
  filter(Year > 2011)

## These two data frames are the same 
all.equal(birds_and_horses, birds_and_horses2)
```

For completeness, this also works

```{r}
birds_and_horses3 <- animals %>% 
  filter((Type == "Bird"|Type == "Horse") & Year > 2011)

all.equal(birds_and_horses, birds_and_horses3)

```

We see here the power of the `,` argument because it is making implicit how the parentheses should work without us accidentally making a mistake. For example 

```{r}
birds_and_horses4 <- animals %>% 
  filter(Type == "Bird"|Type == "Horse" & Year > 2011) 

## Will not be the same. 
all.equal(birds_and_horses, birds_and_horses4)

```

## select()

Now we have a data frame of just rescues of cats and dogs. Suppose we are only interested in a few variables of the data frame. We can use the `select()` function to keep only the variables we select. 

To be concrete, suppose we just want to see the Year, Type, and PropertyCategory variables.

```{r}
cats_and_dogs <- animals %>% 
  filter(Type == "Cat"|Type == "Dog")

cats_and_dogs_short <- cats_and_dogs %>% 
  select(Year, Type, PropertyCategory)
```

If we open up `cats_and_dogs_short`, we'll see that it only contains the Year, Type, and PropertyCategory columns. 

Both the `select()` and `filter()` functions subset the data frame. The difference is that `select()` extracts certain columns, while `filter` extracts certain rows. 

When using `select` and `filter` together, the order of operations is very important. If we used `select()` first, the `filter()` function can only filter on variables that we selected. 

We can also select observation variables using:
  - variable indices
  - variable names (without quotes)
  - `x:z` to select all variables between x and z
  - `-y` to *exclude* y
  - `starts_with(x, ignore.case = TRUE)`: all names that starts with `x`
  - `ends_with(x, ignore.case = TRUE)`: all names that ends with `x`
  - `contains(x, ignore.case = TRUE)`: all names that contain `x`

## group_by()

A `grouped_df` can be thought of as a `list` where each item in the `list` is a `data.frame` containing only the rows that correspond to the particular value `continent` (at least in the example above).

Let's demonstrate the benefits of `group_by` by answering the question, "What are total number of cat rescues for each borough?"

```{r}
borough_cat_rescues <- animals %>% 
  ## group all observations by Boroughs
  group_by(Borough)%>%
  ## get just the observations of cat rescues 
  filter(Type == "Cat")%>%
  ## new function! count the unique values of one or more variables
  count(Type)

head(borough_cat_rescues)
```

We pass `ungroup()` to our data to ungroup our dataset. 

```{r}
animals %>% 
  group_by(Borough)%>%
  filter(Type == "Cat")%>%
  count(Type)%>%
  ungroup()
```

## summarize()

`summarise()` or `summarize()` collapses a data frame to a single row. 

```{r}
animals %>% 
  summarise(avg_rescue_cost = mean(RescueCost, na.rm = T))

## Note that summarise can also be written with a z 
animals %>% 
  summarize(avg_rescue_cost = mean(RescueCost, na.rm = T))
```


`summarise()` becomes extremely useful when paired with `group_by()`. We just saw that our last block gave the average cost across our data set. By using the `group_by()` function, we split our original data frame into multiple pieces, which we then use to run functions (e.g. `mean()`) within `summarize()`. 

Suppose instead we are interested in the average cost of a rescue for each borough. 

```{r}
animals %>% 
  group_by(Borough)%>%
  summarise(avg_rescue_cost = mean(RescueCost, na.rm=T))%>%
  arrange(desc(avg_rescue_cost))
```

We are not limited to grouping by just one variable. We can group by multiple variables. Let's answer the question, "What's the average cost by borough year?" 

```{r}
animals %>% 
  group_by(Borough, Year)%>%
  summarise(avg_rescue_cost = mean(RescueCost, na.rm=T))%>%
  arrange(Borough)

```

That is already quite powerful, but it gets even better! We are not limited to defining one new variable in `summarize()`. Suppose we want to know the average deviation within each borough year. 

```{r}
animals %>% 
  group_by(Borough, Year)%>%
  summarise(avg_rescue_cost = mean(RescueCost, na.rm=T),
            sd_rescue_cost = sd(RescueCost, na.rm = T),
            .groups = "drop_last")%>%
  arrange(Borough)

```

## mutate()

`mutate()` creates new variables to the same data frame that you pass into it. 

To demonstrate `mutate()`, load the `gapminder-FiveYearData.csv` into RStudio as a data frame object called gapminder

```{r}
gapminder <- read_csv(here("R-Data-Wrangling-Module/data/gapminder-FiveYearData.csv"), show_col_types = FALSE)
View(gapminder)
```

The gapminder dataset has six variables and is in tidy form. One of those variables is lifeExp. Imagine we are interested in comparing the difference between a country's life expectancy and the average continent-year-wide life expectancy by year. Such a query requires us to make two new variables. The first variable is the mean continent-year life expectancy. The second variable is the difference between life expectancy for a country and the continent's life expectancy for every year. 

`mutate()` easily handles both cases. We can also use `mutate()` to create new variables before (or even after) summarizing information.

```{r}
gapminder_xtra_vars <- gapminder %>% 
  group_by(year, continent)%>%
  mutate(continent_lifeExp = mean(lifeExp, na.rm = T),
         diff_lifeExp = lifeExp - continent_lifeExp)

```

Note that `mutate()` does not require a `group_by()`. We can simply add a new column, either as a function of existing columns or through a new computation. Here's an example of doing both. 

```{r}
gap_mutate_no_group <- gapminder %>% 
  mutate(gdp_billion = (gdpPercap*pop)/10^9, 
         new_comp = 2+2)
```

A final useful function to know is the how-to count observations within a mutate. `dplyr` provides the handy `n()` function for this computation. Here's an example. 

```{r}
gap_count <- gapminder %>% 
  filter(year == 2007)%>%
  group_by(continent)%>%
  mutate(numCountries = n())%>%
  # distinct works like select() except it returns only rows 
  # that are unique
  distinct(continent, numCountries)%>%
  arrange(desc(numCountries))

```

## pivot_longer()

Until now, we have been using the nicely formatted, original gapminder dataset. Now, let's start with the wide-format version of the gapminder dataset.

```{r}
gap_wide <- read_csv(here("R-Data-Wrangling-Module/data/gapminder_wide.csv"), show_col_types = FALSE)
View(gap_wide)
```

The first step towards getting our nice, *tidy* data format is to convert from the wide to the long format. 

The function `pivot_longer()` will "gather" the observation variables into a single variable.

```{r}
gap_long <- gap_wide %>% 
  pivot_longer(
    cols = 3:38, 
    names_to = "obstype_year",
    values_to = "obs_values"
  )
head(gap_long)
```


Notice that we put three arguments into the `pivot_longer` function: 

1. We want to gather the column indices of the old observation variables (`3:38`, signaling columns 3 through 38) into one variable. Notice that we want to keep columns 1 and 2, as these are considered "ID" variables. 

An alternative way to do indices is to type in the column names of interest explicitly. Here is an example where we exclude the first two columns. 

```{r}
make_Long <- gap_wide %>% 
  pivot_longer(
    cols = c(-continent, -country), 
    names_to = "obstype_year",
    values_to = "obs_values"
  )
head(make_Long)
```

2. the name of the new column for the new ID variable (`obstype_year`), 

3. the name for the new amalgamated observation variable (`obs_value`) 

Alternatively, we can use the column structure in the `gap_wide` data frame to do the same thing with the `starts_with` function.

```{r}
# with the starts_with() function
gap_long <- gap_wide %>%
    pivot_longer(
    cols = c(starts_with('gdpPercap'), 
             starts_with('lifeExp'),
             starts_with('pop')),
    names_to = "obstype_year",
    values_to = "obs_values"
  )
head(gap_long)
```

However you choose to do it, notice that the output collapses all of the measure variables into two columns: one containing the new ID variable, the other containing the observation value for that row. 

## separate()

You'll notice that in our long dataset, `obstype_year` actually contains two pieces of information, the observation type (`pop`, `lifeExp`, or `gdpPercap`) and the `year`.

We can use the `separate()` function to split the character strings into multiple variables:

```{r}
gap_long_sep <- gap_long %>% 
  separate(obstype_year, into = c('obs_type','year'), sep = "_") %>% 
  mutate(year = as.integer(year))
head(gap_long_sep)
```

## pivot_wider()

The opposite of `pivot_longer` is `pivot_wider`. It spreads our observation variables back out to make a wider table. We can use this function to spread our `gap_long()` to the original format.

```{r}
gap_original <- gap_long_sep %>% 
  pivot_wider(
    names_from = obs_type, 
    values_from = obs_values)
head(gap_original)
```